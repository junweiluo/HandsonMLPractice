{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter14Ex02_ResNet34.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHQUaS/ghm3KaWX5NAKZ9Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junweiluo/HandsonMLPractice/blob/master/Chapter14Ex02_ResNet34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_GTYMqcndXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTWkn4PhoIDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_sample_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA-KoKCxoJ5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f6421c54-c232-4c64-84f5-2929694b129f"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - X_mean) / X_std\n",
        "X_valid = (X_valid - X_mean) / X_std\n",
        "X_test = (X_test - X_mean) / X_std\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYtKkK-BofN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
        "                        padding=\"SAME\", use_bias=False)\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConv2D(filters, strides=strides),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            DefaultConv2D(filters),\n",
        "            keras.layers.BatchNormalization()]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
        "                keras.layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4rOm_AAzURG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(DefaultConv2D(64, kernel_size=7, strides=2,\n",
        "                        input_shape=[224, 224, 1])) # you can change the shape of the inputs.\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_KwGA6czfzk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "89394807-b0db-4908-8bc2-7185d114807d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 112, 112, 64)      3136      \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "residual_unit_16 (ResidualUn (None, 56, 56, 64)        74240     \n",
            "_________________________________________________________________\n",
            "residual_unit_17 (ResidualUn (None, 56, 56, 64)        74240     \n",
            "_________________________________________________________________\n",
            "residual_unit_18 (ResidualUn (None, 56, 56, 64)        74240     \n",
            "_________________________________________________________________\n",
            "residual_unit_19 (ResidualUn (None, 28, 28, 128)       230912    \n",
            "_________________________________________________________________\n",
            "residual_unit_20 (ResidualUn (None, 28, 28, 128)       295936    \n",
            "_________________________________________________________________\n",
            "residual_unit_21 (ResidualUn (None, 28, 28, 128)       295936    \n",
            "_________________________________________________________________\n",
            "residual_unit_22 (ResidualUn (None, 28, 28, 128)       295936    \n",
            "_________________________________________________________________\n",
            "residual_unit_23 (ResidualUn (None, 14, 14, 256)       920576    \n",
            "_________________________________________________________________\n",
            "residual_unit_24 (ResidualUn (None, 14, 14, 256)       1181696   \n",
            "_________________________________________________________________\n",
            "residual_unit_25 (ResidualUn (None, 14, 14, 256)       1181696   \n",
            "_________________________________________________________________\n",
            "residual_unit_26 (ResidualUn (None, 14, 14, 256)       1181696   \n",
            "_________________________________________________________________\n",
            "residual_unit_27 (ResidualUn (None, 14, 14, 256)       1181696   \n",
            "_________________________________________________________________\n",
            "residual_unit_28 (ResidualUn (None, 14, 14, 256)       1181696   \n",
            "_________________________________________________________________\n",
            "residual_unit_29 (ResidualUn (None, 7, 7, 512)         3676160   \n",
            "_________________________________________________________________\n",
            "residual_unit_30 (ResidualUn (None, 7, 7, 512)         4722688   \n",
            "_________________________________________________________________\n",
            "residual_unit_31 (ResidualUn (None, 7, 7, 512)         4722688   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 21,300,554\n",
            "Trainable params: 21,283,530\n",
            "Non-trainable params: 17,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Zx6Nf8olw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "c8e8b90a-8ae0-4cbd-d378-8322d4d18726"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "score = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:10] # pretend we have new images\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 1) for input Tensor(\"conv2d_36_input:0\", shape=(None, 224, 224, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 1) for input Tensor(\"conv2d_36_input:0\", shape=(None, 224, 224, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28, 1).\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8218WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 1) for input Tensor(\"conv2d_36_input:0\", shape=(None, 224, 224, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28, 1).\n",
            "1719/1719 [==============================] - 65s 38ms/step - loss: 0.5208 - accuracy: 0.8218 - val_loss: 0.4369 - val_accuracy: 0.8484\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 64s 37ms/step - loss: 0.3640 - accuracy: 0.8715 - val_loss: 0.3864 - val_accuracy: 0.8584\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 63s 37ms/step - loss: 0.3089 - accuracy: 0.8876 - val_loss: 0.3077 - val_accuracy: 0.8892\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 63s 37ms/step - loss: 0.2985 - accuracy: 0.8946 - val_loss: 0.2975 - val_accuracy: 0.8876\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 63s 37ms/step - loss: 0.2697 - accuracy: 0.9042 - val_loss: 0.2919 - val_accuracy: 0.8888\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 63s 37ms/step - loss: 0.2376 - accuracy: 0.9146 - val_loss: 0.2726 - val_accuracy: 0.9012\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 62s 36ms/step - loss: 0.2289 - accuracy: 0.9191 - val_loss: 1.9637 - val_accuracy: 0.5532\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 62s 36ms/step - loss: 0.2127 - accuracy: 0.9224 - val_loss: 0.2525 - val_accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 61s 36ms/step - loss: 0.1794 - accuracy: 0.9340 - val_loss: 0.2733 - val_accuracy: 0.9046\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 61s 36ms/step - loss: 0.1684 - accuracy: 0.9386 - val_loss: 0.2610 - val_accuracy: 0.9090\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2741 - accuracy: 0.9062\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 1) for input Tensor(\"conv2d_36_input:0\", shape=(None, 224, 224, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edI-CN1_zeYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUa5CtM9ovyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}