{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.3300e+00,  4.1000e+01,  6.9800e+00,  1.0200e+00,  3.2200e+02,\n",
       "         2.5600e+00,  3.7880e+01, -1.2223e+02],\n",
       "       [ 8.3000e+00,  2.1000e+01,  6.2400e+00,  9.7000e-01,  2.4010e+03,\n",
       "         2.1100e+00,  3.7860e+01, -1.2222e+02],\n",
       "       [ 7.2600e+00,  5.2000e+01,  8.2900e+00,  1.0700e+00,  4.9600e+02,\n",
       "         2.8000e+00,  3.7850e+01, -1.2224e+02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['data'][:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from keras import layers\n",
    "from keras.models import Model\n",
    "# from keras.models import Model # this is same\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# this concatenate is different from merge.Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better specify all tracks of functions in keras\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = ['mean_squared_error','mean_squared_error'], optimizer='adam', loss_weights=[0.9,0.1]) #, metrics=['accuracy','accuracy']) # adam or sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model_callback.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# This checkpoint is saved for computer crashing scenario to restore the model.  \n",
    "# The saved model is not generally used, but only in case of computer crashing.\n",
    "# Not needed for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 2s 130us/sample - loss: 2.2132 - output_loss: 2.1985 - aux_output_loss: 2.3401 - val_loss: 0.8974 - val_output_loss: 0.8922 - val_aux_output_loss: 0.9436\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.8147 - output_loss: 0.7967 - aux_output_loss: 0.9751 - val_loss: 0.6212 - val_output_loss: 0.6146 - val_aux_output_loss: 0.6808\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5426 - output_loss: 0.5289 - aux_output_loss: 0.6657 - val_loss: 0.5281 - val_output_loss: 0.5175 - val_aux_output_loss: 0.6242\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4734 - output_loss: 0.4596 - aux_output_loss: 0.5978 - val_loss: 0.4770 - val_output_loss: 0.4640 - val_aux_output_loss: 0.5939\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4355 - output_loss: 0.4210 - aux_output_loss: 0.5649 - val_loss: 0.4494 - val_output_loss: 0.4354 - val_aux_output_loss: 0.5752\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4162 - output_loss: 0.4019 - aux_output_loss: 0.5438 - val_loss: 0.4261 - val_output_loss: 0.4130 - val_aux_output_loss: 0.5445\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4031 - output_loss: 0.3900 - aux_output_loss: 0.5227 - val_loss: 0.4202 - val_output_loss: 0.4072 - val_aux_output_loss: 0.5368\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4131 - output_loss: 0.4006 - aux_output_loss: 0.5259 - val_loss: 0.4004 - val_output_loss: 0.3881 - val_aux_output_loss: 0.5116\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3727 - output_loss: 0.3614 - aux_output_loss: 0.4739 - val_loss: 0.3901 - val_output_loss: 0.3789 - val_aux_output_loss: 0.4912\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3642 - output_loss: 0.3544 - aux_output_loss: 0.4527 - val_loss: 0.3837 - val_output_loss: 0.3731 - val_aux_output_loss: 0.4791\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3592 - output_loss: 0.3501 - aux_output_loss: 0.4403 - val_loss: 0.3762 - val_output_loss: 0.3667 - val_aux_output_loss: 0.4623\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3637 - output_loss: 0.3550 - aux_output_loss: 0.4427 - val_loss: 0.3814 - val_output_loss: 0.3722 - val_aux_output_loss: 0.4642\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3791 - output_loss: 0.3705 - aux_output_loss: 0.4575 - val_loss: 0.3687 - val_output_loss: 0.3601 - val_aux_output_loss: 0.4471\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3625 - output_loss: 0.3541 - aux_output_loss: 0.4365 - val_loss: 0.3684 - val_output_loss: 0.3595 - val_aux_output_loss: 0.4487\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3458 - output_loss: 0.3381 - aux_output_loss: 0.4141 - val_loss: 0.3621 - val_output_loss: 0.3536 - val_aux_output_loss: 0.4384\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3437 - output_loss: 0.3361 - aux_output_loss: 0.4114 - val_loss: 0.3605 - val_output_loss: 0.3517 - val_aux_output_loss: 0.4400\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3498 - output_loss: 0.3414 - aux_output_loss: 0.4248 - val_loss: 0.3578 - val_output_loss: 0.3491 - val_aux_output_loss: 0.4365\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3453 - output_loss: 0.3376 - aux_output_loss: 0.4157 - val_loss: 0.3546 - val_output_loss: 0.3460 - val_aux_output_loss: 0.4329\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3475 - output_loss: 0.3391 - aux_output_loss: 0.4234 - val_loss: 0.3531 - val_output_loss: 0.3442 - val_aux_output_loss: 0.4334\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3344 - output_loss: 0.3271 - aux_output_loss: 0.4000 - val_loss: 0.3511 - val_output_loss: 0.3427 - val_aux_output_loss: 0.4277\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3329 - output_loss: 0.3257 - aux_output_loss: 0.3996 - val_loss: 0.3664 - val_output_loss: 0.3577 - val_aux_output_loss: 0.4456\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3351 - output_loss: 0.3277 - aux_output_loss: 0.4030 - val_loss: 0.3460 - val_output_loss: 0.3376 - val_aux_output_loss: 0.4223\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3461 - output_loss: 0.3385 - aux_output_loss: 0.4133 - val_loss: 0.3442 - val_output_loss: 0.3360 - val_aux_output_loss: 0.4179\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3283 - output_loss: 0.3213 - aux_output_loss: 0.3924 - val_loss: 0.3433 - val_output_loss: 0.3352 - val_aux_output_loss: 0.4170\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3312 - output_loss: 0.3240 - aux_output_loss: 0.3960 - val_loss: 0.3445 - val_output_loss: 0.3365 - val_aux_output_loss: 0.4170\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3391 - output_loss: 0.3322 - aux_output_loss: 0.4028 - val_loss: 0.3462 - val_output_loss: 0.3383 - val_aux_output_loss: 0.4180\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3299 - output_loss: 0.3219 - aux_output_loss: 0.4018 - val_loss: 0.3429 - val_output_loss: 0.3351 - val_aux_output_loss: 0.4130\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3319 - output_loss: 0.3243 - aux_output_loss: 0.4004 - val_loss: 0.3403 - val_output_loss: 0.3326 - val_aux_output_loss: 0.4099\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3373 - output_loss: 0.3311 - aux_output_loss: 0.3921 - val_loss: 0.3396 - val_output_loss: 0.3320 - val_aux_output_loss: 0.4081\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3271 - output_loss: 0.3205 - aux_output_loss: 0.3899 - val_loss: 0.3414 - val_output_loss: 0.3338 - val_aux_output_loss: 0.4093\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3213 - output_loss: 0.3147 - aux_output_loss: 0.3802 - val_loss: 0.3397 - val_output_loss: 0.3327 - val_aux_output_loss: 0.4039\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3223 - output_loss: 0.3157 - aux_output_loss: 0.3811 - val_loss: 0.3404 - val_output_loss: 0.3329 - val_aux_output_loss: 0.4085\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3227 - output_loss: 0.3160 - aux_output_loss: 0.3825 - val_loss: 0.3336 - val_output_loss: 0.3263 - val_aux_output_loss: 0.4004\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3221 - output_loss: 0.3153 - aux_output_loss: 0.3828 - val_loss: 0.3373 - val_output_loss: 0.3301 - val_aux_output_loss: 0.4029\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3182 - output_loss: 0.3118 - aux_output_loss: 0.3756 - val_loss: 0.3428 - val_output_loss: 0.3359 - val_aux_output_loss: 0.4050\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3166 - output_loss: 0.3101 - aux_output_loss: 0.3742 - val_loss: 0.3316 - val_output_loss: 0.3246 - val_aux_output_loss: 0.3950\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3194 - output_loss: 0.3127 - aux_output_loss: 0.3796 - val_loss: 0.3299 - val_output_loss: 0.3230 - val_aux_output_loss: 0.3922\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3201 - output_loss: 0.3138 - aux_output_loss: 0.3757 - val_loss: 0.3345 - val_output_loss: 0.3271 - val_aux_output_loss: 0.4013\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3144 - output_loss: 0.3084 - aux_output_loss: 0.3693 - val_loss: 0.3290 - val_output_loss: 0.3219 - val_aux_output_loss: 0.3926\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3129 - output_loss: 0.3067 - aux_output_loss: 0.3683 - val_loss: 0.3278 - val_output_loss: 0.3211 - val_aux_output_loss: 0.3881\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3165 - output_loss: 0.3101 - aux_output_loss: 0.3735 - val_loss: 0.3253 - val_output_loss: 0.3188 - val_aux_output_loss: 0.3845\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3179 - output_loss: 0.3123 - aux_output_loss: 0.3676 - val_loss: 0.3379 - val_output_loss: 0.3307 - val_aux_output_loss: 0.4029\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3119 - output_loss: 0.3055 - aux_output_loss: 0.3678 - val_loss: 0.3229 - val_output_loss: 0.3164 - val_aux_output_loss: 0.3816\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3081 - output_loss: 0.3021 - aux_output_loss: 0.3614 - val_loss: 0.3265 - val_output_loss: 0.3200 - val_aux_output_loss: 0.3857\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3094 - output_loss: 0.3036 - aux_output_loss: 0.3610 - val_loss: 0.3313 - val_output_loss: 0.3247 - val_aux_output_loss: 0.3911\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3074 - output_loss: 0.3016 - aux_output_loss: 0.3604 - val_loss: 0.3214 - val_output_loss: 0.3150 - val_aux_output_loss: 0.3787\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3071 - output_loss: 0.3013 - aux_output_loss: 0.3589 - val_loss: 0.3233 - val_output_loss: 0.3169 - val_aux_output_loss: 0.3813\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3074 - output_loss: 0.3015 - aux_output_loss: 0.3600 - val_loss: 0.3242 - val_output_loss: 0.3174 - val_aux_output_loss: 0.3858\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3059 - output_loss: 0.3004 - aux_output_loss: 0.3580 - val_loss: 0.3212 - val_output_loss: 0.3148 - val_aux_output_loss: 0.3791\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3044 - output_loss: 0.2986 - aux_output_loss: 0.3566 - val_loss: 0.3230 - val_output_loss: 0.3168 - val_aux_output_loss: 0.3796\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3040 - output_loss: 0.2989 - aux_output_loss: 0.3545 - val_loss: 0.3228 - val_output_loss: 0.3165 - val_aux_output_loss: 0.3802\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3032 - output_loss: 0.2980 - aux_output_loss: 0.3509 - val_loss: 0.3360 - val_output_loss: 0.3303 - val_aux_output_loss: 0.3876\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3141 - output_loss: 0.3087 - aux_output_loss: 0.3635 - val_loss: 0.3201 - val_output_loss: 0.3134 - val_aux_output_loss: 0.3803\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3090 - output_loss: 0.3030 - aux_output_loss: 0.3617 - val_loss: 0.3174 - val_output_loss: 0.3112 - val_aux_output_loss: 0.3735\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3035 - output_loss: 0.2980 - aux_output_loss: 0.3534 - val_loss: 0.3178 - val_output_loss: 0.3116 - val_aux_output_loss: 0.3744\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.2973 - output_loss: 0.2920 - aux_output_loss: 0.3456 - val_loss: 0.3253 - val_output_loss: 0.3188 - val_aux_output_loss: 0.3843\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.2973 - output_loss: 0.2923 - aux_output_loss: 0.3450 - val_loss: 0.3172 - val_output_loss: 0.3111 - val_aux_output_loss: 0.3721\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.2990 - output_loss: 0.2937 - aux_output_loss: 0.3471 - val_loss: 0.3236 - val_output_loss: 0.3174 - val_aux_output_loss: 0.3794\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.2981 - output_loss: 0.2930 - aux_output_loss: 0.3437 - val_loss: 0.3162 - val_output_loss: 0.3102 - val_aux_output_loss: 0.3708\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3001 - output_loss: 0.2949 - aux_output_loss: 0.3472 - val_loss: 0.3154 - val_output_loss: 0.3094 - val_aux_output_loss: 0.3696\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3000 - output_loss: 0.2947 - aux_output_loss: 0.3480 - val_loss: 0.3239 - val_output_loss: 0.3173 - val_aux_output_loss: 0.3840\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3025 - output_loss: 0.2971 - aux_output_loss: 0.3496 - val_loss: 0.3140 - val_output_loss: 0.3081 - val_aux_output_loss: 0.3680\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.2951 - output_loss: 0.2898 - aux_output_loss: 0.3416 - val_loss: 0.3168 - val_output_loss: 0.3106 - val_aux_output_loss: 0.3722\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.2945 - output_loss: 0.2890 - aux_output_loss: 0.3427 - val_loss: 0.3159 - val_output_loss: 0.3100 - val_aux_output_loss: 0.3698\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.2932 - output_loss: 0.2880 - aux_output_loss: 0.3396 - val_loss: 0.3151 - val_output_loss: 0.3092 - val_aux_output_loss: 0.3688\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.2922 - output_loss: 0.2872 - aux_output_loss: 0.3377 - val_loss: 0.3119 - val_output_loss: 0.3060 - val_aux_output_loss: 0.3654\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.2958 - output_loss: 0.2902 - aux_output_loss: 0.3452 - val_loss: 0.3103 - val_output_loss: 0.3044 - val_aux_output_loss: 0.3636\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.2919 - output_loss: 0.2869 - aux_output_loss: 0.3386 - val_loss: 0.3099 - val_output_loss: 0.3040 - val_aux_output_loss: 0.3633\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.2909 - output_loss: 0.2859 - aux_output_loss: 0.3364 - val_loss: 0.3138 - val_output_loss: 0.3081 - val_aux_output_loss: 0.3658\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.2934 - output_loss: 0.2882 - aux_output_loss: 0.3399 - val_loss: 0.3113 - val_output_loss: 0.3056 - val_aux_output_loss: 0.3629\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.2903 - output_loss: 0.2852 - aux_output_loss: 0.3363 - val_loss: 0.3111 - val_output_loss: 0.3054 - val_aux_output_loss: 0.3625\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.2910 - output_loss: 0.2860 - aux_output_loss: 0.3358 - val_loss: 0.3205 - val_output_loss: 0.3149 - val_aux_output_loss: 0.3716\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.2885 - output_loss: 0.2835 - aux_output_loss: 0.3333 - val_loss: 0.3355 - val_output_loss: 0.3297 - val_aux_output_loss: 0.3878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=100, \n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "# set up checkpoints for callback as well as checkpoint for early stopping\n",
    "# epochs can be big since there is early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping is to avoid overfitting.\n",
    "#For earlystopping there is no need to roll back.  It is automatic.\n",
    "# Only in case of computer crashing, do we need to restore.\n",
    "#model = keras.models.load_model(\"my_keras_model_callback.h5\")\n",
    "# roll back to the best model on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 35us/sample - loss: 0.3022 - output_loss: 0.2976 - aux_output_loss: 0.3318\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3021771017259868"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss  # to compare to validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9171637],\n",
       "        [1.0895746],\n",
       "        [1.3334855]], dtype=float32), array([[1.0556586],\n",
       "        [1.1479523],\n",
       "        [1.3771921]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_modelEx11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.  # check all availabe optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.losses.    # check all available loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.  # check all available metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
