{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.3300e+00,  4.1000e+01,  6.9800e+00,  1.0200e+00,  3.2200e+02,\n",
       "         2.5600e+00,  3.7880e+01, -1.2223e+02],\n",
       "       [ 8.3000e+00,  2.1000e+01,  6.2400e+00,  9.7000e-01,  2.4010e+03,\n",
       "         2.1100e+00,  3.7860e+01, -1.2222e+02],\n",
       "       [ 7.2600e+00,  5.2000e+01,  8.2900e+00,  1.0700e+00,  4.9600e+02,\n",
       "         2.8000e+00,  3.7850e+01, -1.2224e+02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['data'][:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from keras import layers\n",
    "from keras.models import Model\n",
    "# from keras.models import Model # this is same\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# this concatenate is different from merge.Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% This can be run only in Colab.  Remove .notebook to run.  Only show logs running in this book.  Can't be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_05_01-08_41_00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 1.9127 - val_loss: 0.7546\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.6779 - val_loss: 0.6393\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.6108 - val_loss: 0.5997\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5768 - val_loss: 0.5700\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5518 - val_loss: 0.5468\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5321 - val_loss: 0.5282\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5169 - val_loss: 0.5133\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.5045 - val_loss: 0.5000\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4945 - val_loss: 0.4894\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4865 - val_loss: 0.4811\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4799 - val_loss: 0.4746\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4744 - val_loss: 0.4683\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4692 - val_loss: 0.4637\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4653 - val_loss: 0.4591\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4616 - val_loss: 0.4559\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4579 - val_loss: 0.4528\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4550 - val_loss: 0.4496\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4520 - val_loss: 0.4477\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4493 - val_loss: 0.4448\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4468 - val_loss: 0.4421\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4446 - val_loss: 0.4404\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4423 - val_loss: 0.4391\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4404 - val_loss: 0.4365\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4384 - val_loss: 0.4359\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4366 - val_loss: 0.4343\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4353 - val_loss: 0.4327\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4332 - val_loss: 0.4309\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4320 - val_loss: 0.4293\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4304 - val_loss: 0.4274\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4287 - val_loss: 0.4272\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 78674), started 10:05:51 ago. (Use '!kill 78674' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1463623d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better specify all tracks of functions in keras\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 30)           930         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = ['mean_squared_error','mean_squared_error'], optimizer='adam', loss_weights=[0.9,0.1]) #, metrics=['accuracy','accuracy']) # adam or sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model_callback.h5\")\n",
    "#early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 1.2786 - output_loss: 1.2101 - aux_output_loss: 1.8915 - val_loss: 0.6710 - val_output_loss: 0.6346 - val_aux_output_loss: 0.9989\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.5307 - output_loss: 0.4980 - aux_output_loss: 0.8245 - val_loss: 0.4818 - val_output_loss: 0.4540 - val_aux_output_loss: 0.7312\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4479 - output_loss: 0.4245 - aux_output_loss: 0.6579 - val_loss: 0.4388 - val_output_loss: 0.4152 - val_aux_output_loss: 0.6506\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4201 - output_loss: 0.4015 - aux_output_loss: 0.5875 - val_loss: 0.4200 - val_output_loss: 0.3995 - val_aux_output_loss: 0.6041\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4030 - output_loss: 0.3871 - aux_output_loss: 0.5470 - val_loss: 0.4193 - val_output_loss: 0.4000 - val_aux_output_loss: 0.5930\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3918 - output_loss: 0.3776 - aux_output_loss: 0.5197 - val_loss: 0.3985 - val_output_loss: 0.3808 - val_aux_output_loss: 0.5581\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3824 - output_loss: 0.3696 - aux_output_loss: 0.4979 - val_loss: 0.3931 - val_output_loss: 0.3774 - val_aux_output_loss: 0.5341\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3914 - output_loss: 0.3811 - aux_output_loss: 0.4858 - val_loss: 0.3907 - val_output_loss: 0.3751 - val_aux_output_loss: 0.5298\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 0.3712 - output_loss: 0.3607 - aux_output_loss: 0.4653 - val_loss: 0.3840 - val_output_loss: 0.3709 - val_aux_output_loss: 0.5017\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3641 - output_loss: 0.3545 - aux_output_loss: 0.4511 - val_loss: 0.3762 - val_output_loss: 0.3631 - val_aux_output_loss: 0.4944\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10, \n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)),callbacks=[tensorboard_cb]) \n",
    "                    #callbacks=[checkpoint_cb]) #, early_stopping_cb])\n",
    "# set up checkpoints for callback; no early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 25us/sample - loss: 0.3694 - output_loss: 0.3623 - aux_output_loss: 0.4505\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "# remove .notebook when running in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 78674), started 10:06:15 ago. (Use '!kill 78674' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x146b52c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This is to come up with the second model traing for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_05_01-08_41_54'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))\n",
    "#learning rate is different for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: nan - val_loss: nan\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: nan - val_loss: nan\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 78674), started 10:06:42 ago. (Use '!kill 78674' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x146404990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36936398984849916"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss  # to compare to validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_modelEx13.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.  # check all availabe optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.losses.    # check all available loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.  # check all available metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
